


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from collections import Counter
from sklearn.linear_model import LinearRegression
import seaborn as sns
from scipy.stats import pearsonr
print(sns.__version__)

pd.set_option('display.max_colwidth', 30)





csv_file = "../Data/R12-over-10-copies.csv"
df = pd.read_csv(csv_file)
df.rename(columns={'Count':'Copy Num'}, inplace=True)
df.head()





df.shape


sum(df.iloc[:, 0].isnull())


sum(df.iloc[:, 1].isnull())


df.dtypes


# check base type proportions
def base_count(text):
    return dict(Counter(text))   


df['Base Counts'] = df['Sequence'].apply(base_count)

df['A'] = df['Base Counts'].astype(object).apply(lambda x: x.get('A', np.nan))
df['C'] = df['Base Counts'].astype(object).apply(lambda x: x.get('C', np.nan))
df['T'] = df['Base Counts'].astype(object).apply(lambda x: x.get('G', np.nan))
df['G'] = df['Base Counts'].astype(object).apply(lambda x: x.get('T', np.nan))


base_columns = ['A', 'C', 'G', 'T']
colors = ['red', 'green', 'orange', 'purple']
base_colors = dict(zip(base_columns, colors))
df.head().iloc[:, 3:]


df['Length'] = df['Sequence'].apply(len)


sum((np.sum(df[base_columns], axis=1) == df['Length']).isnull()) # Checks base counts add up to length of sequence


allowed_keys = {'A', 'C', 'T', 'G'} # Checks that there are no weird nonstandard bases
df['Nonstandard base'] = df['Base Counts'].astype(object).apply(lambda x: not set(x.keys()).issubset(allowed_keys))
np.sum(df['Nonstandard base'])


df.head()


df['Length'].value_counts().sort_values(ascending=False)





v_df = df # Save a verbose version of df
df = df[['Sequence', 'Length', 'Copy Num', 'A', 'C', 'T', 'G']]
df.head()


for col in base_columns:
    df.loc[:, col] = df[col]/df['Length']


df.head()








df['Copy Num'].describe()





plt.hist(df['Copy Num'].values, bins=92, color='teal')
plt.title('Histogram of the Copy Nums')
plt.yscale('log')
plt.ylabel('Log(Frequency)')
plt.show()








sns.boxplot(df['Copy Num'].values, color='paleturquoise')
plt.show()





df['Length'].describe()





bins = np.linspace(82, 108, 20)
plt.hist(df['Length'], color='violet', bins=bins, edgecolor='indigo')
plt.title('Histogram of the Lengths')
plt.yscale('log')
plt.ylabel('Log(Frequency)')
plt.axvline(x=98, color='navy', linestyle='--', linewidth=2, label='98 bp')
plt.show()








sns.boxplot(df['Length'].values, color='violet')
plt.show()








INIT_FRAC = 0.25

fig, axes = plt.subplots(2, 2, figsize=(10,8), sharex=True, sharey=True)
                        
for base, ax in zip(base_columns, axes.flatten()):
    ax.hist(df[base], color=base_colors[base], edgecolor='black')
    ax.set_title(f'Histogram of %{base}')
    ax.axvline(x=INIT_FRAC, color='skyblue', linestyle='--', linewidth=2)
 
plt.tight_layout()
plt.show()





base_frac_stats = pd.DataFrame([df[base].describe() for base in base_columns])
base_frac_stats['range'] = base_frac_stats['max'] - base_frac_stats['min']
np.round(base_frac_stats, 2)





# save verbose frac stats
v_base_frac_stats = base_frac_stats
base_frac_stats = base_frac_stats.iloc[:, [1, 3, 4, 5, 6, 7]]
base_frac_stats





INIT_FRAC = 0.25
categories = base_frac_stats.columns.values

fig, axes = plt.subplots(2, 2, figsize=(10,8), sharey=True)
                        
for base, ax in zip(base_columns, axes.flatten()):
    values = base_frac_stats.loc[base]
    ax.bar(categories, values, color=base_colors[base])
    ax.axhline(y=INIT_FRAC, color='navy', linestyle='--', linewidth=2)
    ax.set_title(f'Statistics for {base}')

plt.tight_layout()
plt.show()








base_frac_stats


# Find percent difference of these stats from expected even base split
np.round((base_frac_stats - 0.25)/0.25 * 100, 1)











fig, axes = plt.subplots(2, 2, figsize=(10,8))

# Plot Each Base Fraction
for ax, base in zip(axes.flatten(), base_columns):
    ax.scatter(df[base], df['Copy Num'], color=base_colors[base])
    ax.set_xlabel(f'%{base}')
    ax.set_ylabel('Copy Num')

plt.tight_layout()
plt.show()





for base in base_columns:
    corr, p_value =pearsonr(df[base], df['Copy Num'])
    print(f'%{base} - Copy Num Correlation: r={corr:.5f}, p={p_value:.5f}')








corr, p_value = pearsonr(df['Length'], df['Copy Num'])
print(f'Length - Copy Num Correlation: r={corr:.5f}, p={p_value:.5f}')








plt.scatter(df['Length'], df['Copy Num'], color='skyblue')
plt.xlabel('Length')
plt.ylabel('Copy Num')
plt.show()





excl_outliers = df[df['Length'] > 98]
corr, p_value = pearsonr(excl_outliers['Length'], excl_outliers['Copy Num'])
print(f'Excluding outliers\nLength - Copy Num Correlation: r={corr:.5f}, p={p_value:.5f}')





len(df[df['Length'] >= 98]) / df.shape[0]








filtered = df.drop('Sequence', axis=1)
# Compute correlation matrix
corr = filtered.corr()
# Create Heatmap
plt.figure(figsize=(8, 6))
sns.heatmap(corr, annot=True, cmap='coolwarm', linewidths=.5, vmin=-1, vmax=1)
plt.show()











fig, axes = plt.subplots(2, 2, figsize=(10, 8), sharey=True)

# Compute global max variance for consistency
max_variance = max(df[col].var() for col in base_columns)

for col, ax in zip(base_columns, axes.flatten()):
    grouped_variance = df.groupby('Copy Num')[col].var()
    grouped_variance.plot(kind='bar', ax=ax, color=base_colors[col])
    ax.set_title(f'Variance of {col} by Copy Num')
    ax.set_xlabel('Copy Num')
    ax.set_ylabel(f'Variance of {col}')
    ax.set_ylim(0, max_variance * 1.1)
    
plt.tight_layout()
plt.show()
