


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import statsmodels.api as sm
from collections import Counter
from sklearn.linear_model import LinearRegression
import seaborn as sns


csv_file = "../Data/R12-over-10-copies.csv"
df = pd.read_csv(csv_file)
df.head()


df.shape


sum(df.iloc[:, 0].isnull())


sum(df.iloc[:, 1].isnull())


df.dtypes


# check base type proportions
def base_count(text):
    return dict(Counter(text))   


df['Base Counts'] = df['Sequence'].apply(base_count)
# df['Base Counts'][1]['A']
df['A'] = df['Base Counts'].astype(object).apply(lambda x: x.get('A', np.nan))
df['C'] = df['Base Counts'].astype(object).apply(lambda x: x.get('C', np.nan))
df['T'] = df['Base Counts'].astype(object).apply(lambda x: x.get('G', np.nan))
df['G'] = df['Base Counts'].astype(object).apply(lambda x: x.get('T', np.nan))


df.head().iloc[:, 3:]


df['Length'] = df['Sequence'].apply(len)


sum((np.sum(df[['A', 'C', 'T', 'G']], axis=1) == df['Length']).isnull()) # Checks base counts add up to length of sequence


allowed_keys = {'A', 'C', 'T', 'G'} # Checks that there are no weird nonstandard bases
df['Nonstandard base'] = df['Base Counts'].astype(object).apply(lambda x: not set(x.keys()).issubset(allowed_keys))
np.sum(df['Nonstandard base'])


df.head()


df['Length'].value_counts().sort_values(ascending=False)





v_df = df # Save a verbose version of df
df = df[['Sequence', 'Length', 'Count', 'A', 'C', 'T', 'G']]
df.head()


for col in ['A', 'C', 'T', 'G']:
    df.loc[:, col] = df[col]/df['Length']


df.head()








df['Count'].describe()





plt.hist(df['Count'].values, bins=92, color='teal')
plt.title('Histogram of the Counts')
plt.yscale('log')
plt.ylabel('Log(Frequency)')
plt.show()








sns.boxplot(df['Count'].values, color='paleturquoise')
plt.show()





df['Length'].describe()





bins = np.linspace(82, 108, 20)
plt.hist(df['Length'], color='violet', bins=bins, edgecolor='indigo')
plt.title('Histogram of the Lengths')
plt.yscale('log')
plt.ylabel('Log(Frequency)')
plt.axvline(x=98, color='navy', linestyle='--', linewidth=2, label='98 bp')
plt.show()








sns.boxplot(df['Length'].values, color='violet')
plt.show()





# bins = np.linspace(82, 108, 20)
INIT_FRAC = 0.25

fig, axes = plt.subplots(2, 2, figsize=(10,8), sharex=True, sharey=True)
                        
for base, ax in zip(base_columns, axes.flatten()):
    ax.hist(df[base], color=base_colors[base], edgecolor='black')
    ax.set_title(f'Histogram of %{base}')

    
    # values = base_frac_stats.loc[base]
    # ax.bar(categories, values, color=base_colors[base])
    ax.axvline(x=INIT_FRAC, color='skyblue', linestyle='--', linewidth=2)
 
plt.tight_layout()
plt.show()





base_frac_stats = pd.DataFrame([df[base].describe() for base in base_columns])
base_frac_stats['range'] = base_frac_stats['max'] - base_frac_stats['min']
np.round(base_frac_stats, 2)





v_base_frac_stats = base_frac_stats
base_frac_stats = base_frac_stats.iloc[:, [1, 3, 4, 5, 6, 7]]
base_frac_stats





INIT_FRAC = 0.25
categories = base_frac_stats.columns.values

fig, axes = plt.subplots(2, 2, figsize=(10,8), sharey=True)
                        
for base, ax in zip(base_columns, axes.flatten()):
    values = base_frac_stats.loc[base]
    ax.bar(categories, values, color=base_colors[base])
    ax.axhline(y=INIT_FRAC, color='navy', linestyle='--', linewidth=2)
    ax.set_title(f'Statistics for {base}')

plt.tight_layout()
plt.show()





# Find percent difference of these stats from expected even base split
np.round((base_frac_stats.iloc[:, [1, 3, 4, 5, 6, 7]] - 0.25)/0.25 * 100, 1)








fig, axes = plt.subplots(2, 2, figsize=(10,8))

# Plot Each Base Fraction
for ax, base in zip(axes.flatten(), base_columns):
    ax.scatter(df[base], df['Count'], color=base_colors[base])
    ax.set_xlabel(f'%{base}')
    ax.set_ylabel('Count')

plt.tight_layout()
plt.show()





from scipy.stats import pearsonr

for base in base_columns:
    corr, p_value =pearsonr(df[base], df['Count'])
    print(f'%{base} - Count Correlation: r={corr:.5f}, p={p_value:.5f}')








fig, axes = plt.subplots(2, 2, figsize=(10, 8), sharey=True)

# Compute global max variance for consistency
max_variance = max(df[col].var() for col in base_columns)

for col, ax in zip(base_columns, axes.flatten()):
    grouped_variance = df.groupby('Count')[col].var()
    grouped_variance.plot(kind='bar', ax=ax, color=base_colors[col])
    ax.set_title(f'Variance of {col} by Count')
    ax.set_xlabel('Count')
    ax.set_ylabel(f'Variance of {col}')
    ax.set_ylim(0, max_variance * 1.1)
    
plt.tight_layout()
plt.show()












